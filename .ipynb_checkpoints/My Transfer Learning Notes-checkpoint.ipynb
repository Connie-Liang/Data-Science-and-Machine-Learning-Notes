{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Notes \n",
    "Connie Liang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transfer Learning is really powerful and can be used for neural networks in terms of \"borrowing\" pretrained neural networks or weights to build off existing knowledge. \"Situation where what has been learned in one setting is exploited to improve generalization in another setting\". \n",
    "\n",
    "\n",
    "- For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks\n",
    "\n",
    "\n",
    "- \"After supervised learning, transfer learning will be the next driver of ML commercial success\" - Andrew Ng\n",
    "\n",
    "\n",
    "- \"the key motivation...is the fact that most models which solve complex problems need a whole lot of data, and getting vast amounts of labeled data for supervised models can be really difficult, considering the time and effort it takes to label data points.\" -Dipanjan Sarkar\n",
    "    \n",
    "    - transfer learning is particularly useful if you don't have a lot of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- for neural networks, TL will either mean:\n",
    "\n",
    "    - training your architecture and weights on one thing and then transferring those weights and architecture to your specific problem, or \n",
    "    \n",
    "    - using a pre-made architecture that has already been trained on a massive dataset (ex: ImageNet) to extract features and then use those features in another ML model training your data, or let the weights change for your specific data\n",
    "\n",
    "\n",
    "- for example, if you have a project that you're trying to classify accents on, but your primary dataset exhibits audio where the audio is not distinct enough, you may apply TL by first training your data on a smaller data set that is much more distinct in accent, and then using that trained neural network to train the primary network.\n",
    "\n",
    "\n",
    "- or, if you were trying to classify dog breeds using 50k images featuring 188 dog breeds. A CNN model might have only an accuracy of 3%. Then, using a pretrained architecture called Xception (designed for image classification, same architecture meaning the number of layers and convolutions) your accuracy jumps to 64%. Then, you fine tune by using pre-trained weights as well from ImageNet and including a very low learning rate, now your test accuracy jumps to 87%. \n",
    "\n",
    "### This is the power of TL in taking data with tons of classifications and still being able to use black box models in a customized way to easily build an effective image classification machine learning model. \n",
    "\n",
    "Particularly in the category of image classification, there have been tremendous new breakthroughs done with TL. Exciting!! In terms of other branches of data science/machine learning, NLP/linguistics has had breakthroughs w GPT2 and GPT3. And so many of these black box models are open source and public!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Pre-trained Neural Network:\n",
    "\n",
    "There are usually two ways:\n",
    "\n",
    "1. slicing and dicing the architecture layers of a pre-trained NN to then train your model on. For example, you might use only the first part of a NN architecture, and then building the second half yourself. Or you could take the output of the pre-trained NN, and incorporate them as features for your new model.\n",
    "    \n",
    "      for example: \n",
    "      \n",
    "      in the case of using a pretrained CNN model for classifying bears, to then classify dogs, you may use the first part of the CNN model but discard the back part because in a CNN model, the initial architecture examines more general features and patterns such as lighting, background, shape of object. In the later part of the model is where the architecture examines more specialized features like eyes, nose. So we can chop off the part of the architecture that is applicable to our problem and then run a random forest on top of that.\n",
    "    \n",
    "    \n",
    "2. or...instead of messing with the actual structure of the NN architecture, you just recalibrate the weights\n",
    "\n",
    "    for example:\n",
    "    \n",
    "    in the case of using a pretrained CNN model for classifying bears, you would not take anything apart from the architecture, but you would instead replace the top layer with a different activation (sigmoid, relu, tan, softmax, etc) and adjust the output neurons (from 3 diff types of bears outcomes to 2 outcomes, bulldog or note bulldog), learning rate, and epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Black Box NN Models\n",
    "\n",
    "- Resnet: commonly used for image prediction, architecture is made up of 34 layers. Resnet is unique in that it has the outputs from one layer as inputs to a layer after the convulation.\n",
    "\n",
    "\n",
    "- Inception Net: a NN made by Google that will run multiple convolutions at the same time, multiple times, and stack them together. So for ex: from the previous layer, it will run a 1x1 convolution, 3x3 convolution, and a 5x5 convolution, then combine them into a new layer and repeat the process.\n",
    "\n",
    "## Where to Find These Black Box NN Models\n",
    "\n",
    "https://keras.io/api/applications/\n",
    "\n",
    "https://modelzoo.co\n",
    "\n",
    "Let's check out the VGG16 model from keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(250,250,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 250, 250, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 250, 250, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 250, 250, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 125, 125, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 125, 125, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 125, 125, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 62, 62, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 62, 62, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 62, 62, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 31, 31, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 31, 31, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 31, 31, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
